{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-input": true,
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nnp.random.seed(2)\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "77a153ea7baaaa1332d836c7ec5fbd0b51577353"
      },
      "cell_type": "markdown",
      "source": "**<font size = 4px>This Model currently running is Model 1G, which is a 4 Block ResNet, connected to 2 fully connected layers. </font>**   \nTraining Acc =  99.23%   \nValidation Acc = 99.57%"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e2dd2a66769b8b5aed2ed7383e822e878405efda"
      },
      "cell_type": "markdown",
      "source": "**Importing **\n---------"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "_kg_hide-input": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nimport itertools\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import Adagrad\nfrom keras.optimizers import Nadam",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "d244d4323d4d688f1ecc4ec9a87f32fe272dcdba",
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")\nsubm = pd.read_csv(\"../input/predict/nas.csv\") ## Upload Test Set",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "scrolled": false,
        "_uuid": "5ee5be09173fca81286122adcdb63a58f374f3cf",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "Y_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1) # Takes Data But Leaves Label Behind  \nY_train.value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "48752dba15e62f1e1121f6b24046c04eb85d93c2"
      },
      "cell_type": "markdown",
      "source": "**Normalize Data**\n-----------------------"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "be12f1540017dbb3c9e2dd4c01c6869d6b721d44",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "X_train = X_train / 255.0\ntest = test / 255.0        ## Range of values was 0-255; now is 0-1.\nsubm = subm/ 255.0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f7874f92c8ff2e318c8afb4b2de18be3957965d"
      },
      "cell_type": "markdown",
      "source": "**Arranging Data To Suite The Keras Requirements**\n------------------------\n"
    },
    {
      "metadata": {
        "_uuid": "0b19e54ffed5702677f2d686af873bea49f27767"
      },
      "cell_type": "markdown",
      "source": "<font size=3>To use the build model function we need to change our 1D 784 bit (28x28) representation of the image into a 3D represntation of the image with:</font>\n"
    },
    {
      "metadata": {
        "_uuid": "4d93e8e1ba327308a1e6d78c93e67b1202be6975"
      },
      "cell_type": "markdown",
      "source": "\n<font size=3>*Height = 28 px   \nWidth = 28 px   \nChannel = 1* </font>\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02c542fe73069b030a2ccdfdf371847ba40fcdab",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "X_train = X_train.values.reshape(-1,28,28,1)\nsubm = subm.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2adeec9c2991c986c4ed70e9dd135856e570fdfd"
      },
      "cell_type": "markdown",
      "source": "**Encoding Using One Hot**\n--------------"
    },
    {
      "metadata": {
        "_uuid": "15220158bcb548b9d76c9d32773bea1d87027622"
      },
      "cell_type": "markdown",
      "source": "<font size=3px> We need to encode our text labels into vectors, hence we still use one hot encoding to do such.  </font>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ced7313318dd53582dc9214178e8682037bce0b5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "\nLabels= [\"0\",\"1\", \"2\",\"3\", \"4\",\"5\", \"6\",\"7\", \"8\",\"9\"]  # Labels\nY_train = pd.get_dummies( Y_train, columns = Labels )  # Encoding of Labels\nY_train = Y_train.values   #Change into Numpy ndarray for model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "03600e37bc6f5f5c45a79e334912527563431e96"
      },
      "cell_type": "markdown",
      "source": "**Data Split & Augumentation**\n--------"
    },
    {
      "metadata": {
        "_uuid": "686fc74e4c14d35c42e8e6cba8bb9a117d1997d3"
      },
      "cell_type": "markdown",
      "source": "<font size=3px>Splitting data throughout training & validation data subsets. Ratio used for training to validation was  80 to 20 respectively. </font>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2824e9a099426e3523c8229564a6e420907ee17e",
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#DrawMe = plt.imshow(X_train[0][:,:,0])  #[Index Of Number][Y,X,Channel]                     ## ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d3c299b1f2f7b7c6e7327d66762fbcdc5faa859c"
      },
      "cell_type": "code",
      "source": "random_seed = 2\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6b1c9b04d32aff37006c35afb19181656ec31949"
      },
      "cell_type": "markdown",
      "source": "**Model Design** \n-------------------"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "5a916133d757d0ea8a0b348dfed4144a20632da8"
      },
      "cell_type": "code",
      "source": "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Softmax, Add, Flatten, Activation , Dropout\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9090b5890e01dc9ad67df5b8cda6838cc3851205"
      },
      "cell_type": "markdown",
      "source": "**Model #1 -     1 Block ResNet **"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2044bf0e022a74048d79c3548144fbce94390acd",
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "inp = Input(shape=(28,28,1)) ## Model #1 - 1 Block ResNet \nC = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(inp)\n\n\n\nC11 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(C)\nC12 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(C11)\nS11 = Add()([C12, C])\n\n\nC12 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(S11)\nM51 = MaxPool2D(pool_size=(2,2), strides=(2,2))(C12)\n\nF1 = Flatten()(M51)\nD1 = Dense(32)(F1)\nA6= Activation(\"relu\")(D1)\nD2 = Dense(256)(A6)\nD3 = Dense(10)(D2)\nA7 = Softmax()(D3)\nmodel = Model(inputs=inp, outputs=A7)\nmodel.summary()\n"
    },
    {
      "metadata": {
        "_uuid": "e20cb16a4c381c5092500293c17852c2e34d9dd5"
      },
      "cell_type": "markdown",
      "source": "**Model #1B -     2 Block ResNet **"
    },
    {
      "metadata": {
        "_uuid": "288c9f2fa637690e7e581ee6b7d0f0fceed5c811"
      },
      "cell_type": "markdown",
      "source": "inp = Input(shape=(28,28,1)) ## Model #1 - 1 Block ResNet \nC = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(inp)\n\n\n\nC11 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(C)\nC12 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(C11)\nS11 = Add()([C12, C])\n\nC21 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(S11)\nC22 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(C21)\nS21 = Add()([C22, S11])\n\n\nCXX = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(S21)\nM51 = MaxPool2D(pool_size=(2,2), strides=(2,2))(CXX)\n\nF1 = Flatten()(M51)\nD1 = Dense(32)(F1)\nA6= Activation(\"relu\")(D1)\nD2 = Dense(256)(A6)\nD3 = Dense(10)(D2)\nA7 = Softmax()(D3)\nmodel = Model(inputs=inp, outputs=A7)\nmodel.summary()\n"
    },
    {
      "metadata": {
        "_uuid": "04802d5816db8bc12d3feb614e9fb151f758b9e1"
      },
      "cell_type": "markdown",
      "source": "**Model #1G-     4 Block ResNet **\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "429875427c9ed6efcfd4f2169ff6a1e635c960de",
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "inp = Input(shape=(28,28,1)) ## Model #1 - 4 Block ResNet \nC = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(inp)\n\n\nC11 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(C)\nC12 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(C11)\nS11 = Add()([C12, C])\n\nC21 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(S11)\nC22 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(C21)\nS21 = Add()([C22, S11])\n\nC31 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(S21)\nC32 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(C31)\nS31 = Add()([C32, S21])\n\nC41 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(S31)\nC42 = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(C41)\nS41 = Add()([C42, S31])\n\nCXX = Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1))(S41)\nM51 = MaxPool2D(pool_size=(2,2), strides=(2,2))(CXX)\n\nF1 = Flatten()(M51)\nD1 = Dense(32)(F1)\nA6= Activation(\"relu\")(D1)\nDD1 = Dropout(0.2)(A6)\nD2 = Dense(64)(DD1)\nDD2 = Dropout(0.2)(D2)\nD3 = Dense(10)(DD2)\nA7 = Softmax()(D3)\nmodel = Model(inputs=inp, outputs=A7)\nmodel.summary()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8112d2f70063e7778d77e8028fb376530167b39c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "optimizer = Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "db3900e6d221975a4b06c3180b538a23de3f1bdd",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3bcf8247967a9c48b85a5d8408fbe9e961fa2fa1",
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3,  verbose=1, factor=0.5,  min_lr=0.00001)\nepochs = 40 #10 # 1\nbatch_size = 86 #256\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n                              , callbacks=[learning_rate_reduction])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bd8003981d6b2565784c9c5a263a19084b1d02e5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "yxy=np.argmax(model.predict(subm),axis=1)\nStringLabel = (['Zero','One','Two','Three','Four','Five','Six','Seven','Eight','Nine'])\npd.Series(yxy,name=\"Label\")\nfor x in yxy:\n    print(x,\"-\", StringLabel[x])",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}